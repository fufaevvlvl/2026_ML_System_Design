{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5440f37",
   "metadata": {},
   "source": [
    "**VI. Эксплуатация**\n",
    "\n",
    "Лекция 8. Деплоймент/развертка моделей. Введение в Deployment. Batch и online предсказание. Паттерны развертывания\n",
    "\n",
    "Лекция 9. Практика\n",
    "\n",
    "Лекция 10. Практика\n",
    "\n",
    "Лекция 11. Оптимизация Inference\n",
    "\n",
    "Чип Хьюэн Глава 10. Инфракструктура\n",
    "\n",
    "Лекция 12. Практика\n",
    "\n",
    "Лекция 13. Практика\n",
    "\n",
    "Лекция 14. Практика ML в ecom\n",
    "\n",
    "**Бонус: человеческий фактор в МЛ**\n",
    "\n",
    "Лекция 15. Этика ИИ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558be56",
   "metadata": {},
   "source": [
    "# Лекция 8. Деплоймент/развертка моделей. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045280c",
   "metadata": {},
   "source": [
    "## Введение в Deployment\n",
    "\n",
    "Deployment - процесс внедрения обученной ML-модели в production среду, где она может принимать реальные данные и делать предсказания для бизнес-приложения. Непрерывный процесс, включающий мониторинг, обновление, масштабирование.\n",
    "\n",
    "Требования production:\n",
    "\n",
    "    низкая latency (<100 мс)\n",
    "    \n",
    "    высокая throughput (тысячи запросов/сек)\n",
    "    \n",
    "    Reliability (99.9%+uptime)\n",
    "    \n",
    "    Scalability (автомасштабирование под нагрузку)\n",
    "    \n",
    "    Cost efficiency (оптимизация вычислительных ресурсов)\n",
    "    \n",
    "Проблемы интеграции \n",
    "\n",
    "    различные форматы моделей (PyTorch, TensorFlow)\n",
    "    \n",
    "    разные языки (python&Go)\n",
    "    \n",
    "    версионирование моделей\n",
    "    \n",
    "    A/B тестирование\n",
    "    \n",
    "    Мониторинг деградации качества\n",
    "    \n",
    "Жизненный цикл модели в production\n",
    "\n",
    "    Обучение модели\n",
    "    \n",
    "    Офлайн оценка\n",
    "    \n",
    "    Подготовка (сериализация, оптимизация)\n",
    "    \n",
    "    Работа в тестовом режиме на ограниченном числе пользователей (Canary deploy/Shadow mode)\n",
    "    \n",
    "    A/B тестирование\n",
    "    \n",
    "    Полное развертывание\n",
    "    \n",
    "    Мониторинг\n",
    "    \n",
    "    Переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40554b9a",
   "metadata": {},
   "source": [
    "## Batch vs Online Prediction\n",
    "\n",
    "**Batch prediction** - для большого набора данных предсказания генерируются заранее.\n",
    "\n",
    "Характеристики:\n",
    "\n",
    "    Периодическое выполнение\n",
    "    \n",
    "    Сохраняются в БД/кеше\n",
    "    \n",
    "    Сглаживает нагрузку и оптимизирует использование ресурсов\n",
    "    \n",
    "    НО! предсказания устаревают и их где-то надо хранить\n",
    "    \n",
    "**Online prediction**\n",
    "\n",
    "Характеристики\n",
    "\n",
    "    Синхронный вызов API\n",
    "    \n",
    "    Низкая latency\n",
    "    \n",
    "    Обрабатывает небольшие батчи за раз\n",
    "    \n",
    "    Свежие предсказания на актуальных данных\n",
    "    \n",
    "**Streaming prediction** - непрерывная обработка потока данных (система готова к поступлению новых данных)\n",
    "\n",
    "    Асинхронная обработка\n",
    "    \n",
    "    Модель обрабатывает события по мере поступления\n",
    "    \n",
    "    Результаты отправляются в другие системы\n",
    "    \n",
    "    Высокая пропускная способность\n",
    "    \n",
    "    Развязываем сервиси-производители и сервисы-потребители\n",
    "\n",
    "**Hybrid подход**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4a288",
   "metadata": {},
   "source": [
    "## Паттерны развертывания моделей\n",
    "\n",
    "Развертывание в облаке или на устройстве?\n",
    "\n",
    "|Облако|Устройство|\n",
    "|-|-|\n",
    "|Простота развертывания и управления с помощью облачных служб|Развертывание модели\n",
    "на устройстве может быть сложным|\n",
    "|Затраты на облачные ресурсы могут быть высокими|Вычисления выполняются на устройстве, нет затрат на аренду облачных ресурсов|\n",
    "|Есть сетевая задержка|Нет сетевой задержки|\n",
    "|Обычно ответ выдается быстрее благодаря использованию более мощного оборудования|Модели МО работают медленнее|\n",
    "|Меньше ограничений|Больше ограничений по памяти, потреблению аккумулятора и т. д.|\n",
    "|Конфиденциальность ослабляется, потому что пользовательские данные переносятся в облако|Более высокий уровень конфиденциальности, потому что данные не покидают устройство|\n",
    "|Чтобы отправлять и получать данные из облачных служб, необходимо подключение к интернету|Подключение к интернету не требуется|\n",
    "\n",
    "Также есть фреймворки для разворачивания ml-модели в браузере\n",
    "\n",
    "\n",
    "1. Модель как сервис\n",
    "\n",
    "    Client + API + Model Service + Model\n",
    "    \n",
    "    fastapi\n",
    "    \n",
    "    зависит от сети\n",
    "    \n",
    "2. Встроенная модель\n",
    "\n",
    "    Интегрирована с приложением\n",
    "    \n",
    "    не зависит от сети, может работать оффлайн\n",
    "    \n",
    "3. Модель как звисимость\n",
    "\n",
    "    Модель загружается как библиотека/пакет, скажем, в корпоративном хранилище\n",
    "    \n",
    "4. Предрасчитанные данные\n",
    "    \n",
    "    Все возможные предсказания просчитали заранее\n",
    "    \n",
    "    Холодные старты, малое число товаров, пиковая нагрузка\n",
    "    \n",
    "5. Федеративное обучение.\n",
    "\n",
    "    Модель обучается на устройствах пользователей без отправки данных на сервер\n",
    "    \n",
    "    Секретность! Т9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e961b",
   "metadata": {},
   "source": [
    "## Непрерывное обучение\n",
    "\n",
    "Если дообучать модель на каждой новой порции данных\n",
    "\n",
    "    Стоимость\n",
    "    \n",
    "    Катастрофическая забывчивость\n",
    "    \n",
    "    Восприимчивость к аномалиям\n",
    "    \n",
    "Новую модель надо протестировать! Желательно, сохранив предыдущее состояние.\n",
    "\n",
    "Непрерывное обучение необходимо, когда идут редкие события, холодный старт (обучение без начальных данных). Частота обновления модели - тонкий вопрос.\n",
    "\n",
    "Проблемы непрерывного обучения\n",
    "\n",
    "    Доступ к новым данным\n",
    "    \n",
    "    Оценки\n",
    "    \n",
    "    Алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e62d805",
   "metadata": {},
   "source": [
    "## Тестирование при эксплуатации\n",
    "\n",
    "Единственный способ убедиться, что модель показывает хорошие результаты при эксплуатации, — протестировать ее на реальном трафике.\n",
    "\n",
    "    Теневое развертывание \n",
    "    \n",
    "        В этом варианте новая модель развертывается параллельно с существующей. Каждый входной запрос передается обеим моделям, но пользователь получает предсказания только от существующей модели.\n",
    "        \n",
    "    A/B-тестирование\n",
    "\n",
    "        В таком формате тестирования новая модель развертывается параллельно с существующей. Часть трафика передается новой модели, а остальные запросы — существующей\n",
    "        \n",
    "    Канареечный релиз\n",
    "    \n",
    "        Постепенное непрерывное рпспространение новой модели\n",
    "        \n",
    "    Тестирование чередованием\n",
    "    \n",
    "        Предложим пользователю на выбор оба варианта (Ничего не напоминает? RLHF и арены LLM)\n",
    "        \n",
    "    (Многорукие) бандиты\n",
    "    \n",
    "        надо было ботать тервер и случайные процессы...\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff0d27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea423b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd0ada7",
   "metadata": {},
   "source": [
    "# Лекция 11. Оптимизация Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebafefdf",
   "metadata": {},
   "source": [
    "## Оптимизация Inferece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43213e6",
   "metadata": {},
   "source": [
    "Оптимизация важна - у нас есть влияние скорости работы на бизнес/загруженность ресурсов. Лишние вычисления=потери. \n",
    "\n",
    "Цели:\n",
    "\n",
    "    снижение latency\n",
    "    \n",
    "    увеличение throughput (количество предсказаний/сек)\n",
    "    \n",
    "    уменьшение занятой памяти\n",
    "    \n",
    "    снижение издержек (износ CPU/GPU)\n",
    "    \n",
    "Методы оптимизации:\n",
    "\n",
    "    Batching (группировка в батчи)\n",
    "    \n",
    "        эффективнее использует ресурсы НО оптимальный батч надо подбирать по обстоятельствам\n",
    "        \n",
    "        увеличивает throughput НО увеличивает latency\n",
    "        \n",
    "    Старое доброе Model Cashing - если много повторяющихся запросов\n",
    "    \n",
    "    Оптимизация на железе - Специализированное оборудование (TPU для TensorFlow например)\n",
    "        \n",
    "    Inference optimization libraries\n",
    "    \n",
    "    Параллелизация\n",
    "    \n",
    "    Оптимизация кода (использование встроенных оптимизированных функций, оптимизация циклов,   )\n",
    "    \n",
    "    Оптимизация ML-моделей (специфические для конкретной архитектуры эвристики)\n",
    "    \n",
    "    Сжатие моделей    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0efa79",
   "metadata": {},
   "source": [
    "## Сжатие моделей\n",
    "\n",
    "Большие модели не влезают в память и медленно работают.\n",
    "\n",
    "    Квантование (уменьшаем точность висов/тренируем сразу с квантованием)\n",
    "    \n",
    "    Pruning - удаление 'лишних' весов\n",
    "    \n",
    "    Дистилляция - обучение маленькой модели имитировать большую модель\n",
    "    \n",
    "    LoRA Factorization\n",
    "    \n",
    "    Экзотика: Neural Architecture Search - AutoML technique that automates the design of artificial neural networks, reducing human intervention to create optimized, efficient models for specific tasks.\n",
    "    \n",
    "Best practice:\n",
    "\n",
    "    комбинирование нескольких техник"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6729e",
   "metadata": {},
   "source": [
    "## Очереди сообщений\n",
    "\n",
    "Message Broker - архитектурный паттерн в распределенных системах. Приложение, которое преобразует сообщение по одному протоколу от приложения-источника к протоколу приложения-приемника.\n",
    "\n",
    "Типы взаимодействия приложений:\n",
    "\n",
    "    point-to-point одно приложение обращается к другому\n",
    "    \n",
    "    push/sub одно приложение оставляет сообщение, другое его забирает\n",
    "\n",
    "Как организовать общение между разными приложениями? Что делать, если одно приложение упало? Нужен единый брокер\n",
    "\n",
    "    Интеграция систем с разными протоколами\n",
    "    \n",
    "    Маршрутизация сообщений\n",
    "    \n",
    "    Надежное хранение\n",
    "    \n",
    "    Гарантия доставки\n",
    "    \n",
    "    Масштабирование\n",
    "    \n",
    "    Преобразование сообщений\n",
    "    \n",
    "    Интеграция с внешними источниками\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c7e5a",
   "metadata": {},
   "source": [
    "# Чип Хьюэн Глава 10. Инфракструктура\n",
    "\n",
    "Хранение и вычисление, ML-платформа\n",
    "\n",
    "    В облаке, или на носителе, своими GPU?\n",
    "\n",
    "Управление ресурсами\n",
    "\n",
    "    планировщик, оркестратор\n",
    "\n",
    "Управление рабочим процессом\n",
    "\n",
    "    airflow, kuberflow\n",
    "\n",
    "Среда разработки\n",
    "\n",
    "    нужно версионирование (Git, MlFlow), нужна стандартизация хотя бы в рамках команды,\n",
    "\n",
    "Развертывание\n",
    "\n",
    "    Docker, Kubernetes, специализированные сервисы\n",
    "    \n",
    "Архив \n",
    "\n",
    "    Хранилище моделей, хранилище признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e99ca",
   "metadata": {},
   "source": [
    "# Лекция 15. Этика ИИ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b168cc1",
   "metadata": {},
   "source": [
    "Кто ставит подпись? Кто должен нести ответственность за решение, принятое ИИ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c69089",
   "metadata": {},
   "source": [
    "Согласованность. Результаты работы модели не должны (сильно) противоречить друг другу. Если модель будет давать каждый раз новые фильтры, как найти понравившийся?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a498fa",
   "metadata": {},
   "source": [
    "Что нужно проверять при взаимодействии с ИИ\n",
    "\n",
    "    проверка на bias\n",
    "    \n",
    "    проверка на неучтенные группы\n",
    "    \n",
    "    независимая аналитика\n",
    "    \n",
    "    прозрачность работы модели\n",
    "    \n",
    "    шифрование и анонимизация\n",
    "    \n",
    "    план отката\n",
    "    \n",
    "    план мониторинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35af1e0",
   "metadata": {},
   "source": [
    "О роли команды.\n",
    "\n",
    "    От универсальной команды, до набора узкоспециализированных команд\n",
    "    \n",
    "    Кто главный?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa3257",
   "metadata": {},
   "source": [
    "Ответственный ИИ: примеры проблем\n",
    "\n",
    "    Дискриминация по расе полу (модель впитала не совсем политкорректный bias)\n",
    "    \n",
    "    Постановка неправильной цели\n",
    "    \n",
    "    Отсутствие прозрачности\n",
    "    \n",
    "    Утечки конфиденциальных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f940b07",
   "metadata": {},
   "source": [
    "Best Practice:\n",
    "\n",
    "    Предполагать, откуда могут прийти искажения. Обучающие данные? Неправильная цель?\n",
    "    \n",
    "    Понимание ограничений, искусство компромиссов\n",
    "    \n",
    "    Продумывать заранее\n",
    "    \n",
    "    Версионирование. (данные, метрики, цели, этические соображения, предупреждения и рекомендации)\n",
    "    \n",
    "    Следить за тенденциями в ответственном ИИ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
